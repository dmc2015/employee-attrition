{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4).pprint\n",
    "\n",
    "data_file_path = '../data/ibm-hr-analytics-attrition-dataset.zip'\n",
    "encoding = 'utf-8-sig'\n",
    "\n",
    "\n",
    "data = []\n",
    "with zipfile.ZipFile(data_file_path) as zfile:\n",
    "    for name in zfile.namelist():\n",
    "        with zfile.open(name) as readfile:\n",
    "            for line in io.TextIOWrapper(readfile, encoding):\n",
    "                data.append(line.replace('\\n', '').split(','))\n",
    "\n",
    "labels=['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department', \n",
    "       'DistanceFromHome', 'Education', 'EducationField', 'EducationField'\n",
    "       \"EmployeeCount\",\"EmployeeNumber\",\"EnvironmentSatisfaction\",\"Gender\",\"HourlyRate\",\"JobInvolvement\",\n",
    "       \"JobLevel\",\"JobRole\",\"JobSatisfaction\",\"MaritalStatus\",\"MonthlyIncome\",\"MonthlyRate\",\"NumCompaniesWorked\",\n",
    "       \"Over18\",\"OverTime\",\"PercentSalaryHike\",\"PerformanceRating\",\"RelationshipSatisfaction\",\"StandardHours\",\n",
    "       \"StockOptionLevel\",\"TotalWorkingYears\",\"TrainingTimesLastYear\",\"WorkLifeBalance\",\"YearsAtCompany\",\n",
    "       \"YearsInCurrentRole\",\"YearsSinceLastPromotion\",\"YearsWithCurrManager\"\n",
    "      ]\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "attrition_df = pd.DataFrame(data, columns=labels)\n",
    "attrition_df = attrition_df.drop([0])\n",
    "\n",
    "\n",
    "attrition_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# attrition_df\n",
    "attrition_df.head()\n",
    "\n",
    "# len(attrition_df.columns)\n",
    "\n",
    "not_categorical_data = [\n",
    "    \"Attrition\",\n",
    "    \"BusinessTravel\",\n",
    "    \"Department\",\n",
    "    \"EducationField\",\n",
    "    \"Gender\",\n",
    "    \"JobRole\",\n",
    "    \"MaritalStatus\",\n",
    "    \"OverTime\",\n",
    "    \"Over18\"\n",
    "]\n",
    "\n",
    "# for data in not_categorical_data:\n",
    "#     print(data , ':', attrition_df[data].unique())\n",
    "    \n",
    "pre_categorized_data = [\"Education\",\n",
    "\"EnvironmentSatisfaction\",\n",
    "\"JobInvolvement\",\n",
    "\"JobSatisfaction\",\n",
    "\"PerformanceRating\",\n",
    "\"RelationshipSatisfaction\",\n",
    "\"WorkLifeBalance\", \n",
    "\"Gender\",\n",
    "\"JobRole\",\n",
    "\"StockOptionLevel\"\n",
    "]\n",
    "\n",
    "#finding categorized data that has no signficance, has only one data value\n",
    "# for data in pre_categorized_data:\n",
    "#     if ( len(attrition_df[data].unique()) <= 1):\n",
    "#         print(data , ':', attrition_df[data].unique())\n",
    "        \n",
    "# #looking at all pre_categorized data unique values\n",
    "# for data in pre_categorized_data:\n",
    "#     print(data , ':', attrition_df[data].unique())\n",
    "    \n",
    "#finding not_categorical_data that has no signficance, has only one data value\n",
    "# for data in not_categorical_data:\n",
    "#     if ( len(attrition_df[data].unique()) <= 1):\n",
    "#         print(data , ':', attrition_df[data].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Categorized Categorical Data\n",
    "\n",
    "Education\n",
    "1 'Below College' 2 'College' 3 'Bachelor' 4 'Master' 5 'Doctor'\n",
    "\n",
    "EnvironmentSatisfaction\n",
    "1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n",
    "\n",
    "JobInvolvement \n",
    "1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n",
    "\n",
    "JobSatisfaction 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n",
    "\n",
    "PerformanceRating \n",
    "1 'Low' 2 'Good' 3 'Excellent' 4 'Outstanding'\n",
    "\n",
    "RelationshipSatisfaction \n",
    "1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n",
    "\n",
    "WorkLifeBalance 1 'Bad' 2 'Good' 3 'Better' 4 'Best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT CATEGORIZED CATEGORICAL DATA\n",
    "post_categorical_data = [\n",
    "    \"Attrition\",\n",
    "    \"BusinessTravel\",\n",
    "    \"Department\",\n",
    "    \"EducationField\",\n",
    "    \"Gender\",\n",
    "    \"JobRole\",\n",
    "    \"MaritalStatus\",\n",
    "    \"OverTime\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "## CHANGING CATEGORICAL DATA TO NUMBERS\n",
    "# VERSION 1\n",
    "# categorical_data_values_count = {}\n",
    "# for data in not_categorical_data:\n",
    "#     #get counts for data\n",
    "#     categorical_data_values_count[data] = attrition_df[data].value_counts()\n",
    "#     #change data to number\n",
    "#     attrition_df[data] = attrition_df[data].factorize()[0]\n",
    "    \n",
    "# attrition_df\n",
    "\n",
    "\n",
    "#VERSION 2\n",
    "# iris['species_num'] = iris.species.map({'Iris-setosa':0, 'Iris-versicolor':1, 'Iris-virginica':2})\n",
    "\n",
    "attrition_df[\"AttritionBool\"] = attrition_df.Attrition.map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "\n",
    "\n",
    "attrition_df[\"TravelRarelyBool\"] = attrition_df.BusinessTravel[attrition_df[\"BusinessTravel\"] == \"Travel_Rarely\"]\n",
    "# attrition_df[\"Travel_Rarely\"] = attrition_df.BusinessTravel.map({\"Travel_Rarely\": 1, \"Travel_Frequently\": 2, \"Non-Travel\": 0})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition_df.columns\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition_df[\"TravelRarelyBool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition_df.Travel_RarelyBool.map({'Travel_Rarely':0, np.nan:1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attrition_df[\"TravelFrequentlyBool\"] = attrition_df.BusinessTravel[attrition_df[\"BusinessTravel\"] == \"Travel_Frequently\"]\n",
    "attrition_df[\"NonTravelBool\"] = attrition_df.BusinessTravel[attrition_df[\"BusinessTravel\"] == \"Non-Travel\"]\n",
    "\n",
    "\n",
    "attrition_df[\"SalesDepartmentBool\"] = attrition_df.Department[attrition_df.Department == \"Sales\"]\n",
    "attrition_df[\"ResearchAndDevelopmentDepartmentBool\"] = attrition_df.Department[attrition_df.Department == \"Research & Development\"]\n",
    "attrition_df[\"HumanResourcesDepartmentBool\"] = attrition_df.Department[attrition_df.Department == \"Human Resources\"]\n",
    "\n",
    "# # attrition_df[\"Department\"] = attrition_df.Department.map({\"Sales\": 0, \"Research & Development\": 1, \"Human Resources\": 2})\n",
    "\n",
    "attrition_df[\"LifeScienceEducationBool\"] = attrition_df.EducationField[attrition_df.EducationField == 'Life Sciences']\n",
    "attrition_df[\"OtherEducationBool\"] = attrition_df.EducationField[attrition_df.EducationField == 'Other']\n",
    "attrition_df[\"MedicalEducationBool\"] = attrition_df.EducationField[attrition_df.EducationField == 'Medical']\n",
    "attrition_df[\"MarketingEducationBool\"] = attrition_df.EducationField[attrition_df.EducationField == 'Marketing']\n",
    "attrition_df[\"TechnicalEducationBool\"] = attrition_df.EducationField[attrition_df.EducationField == 'Technical Degree']\n",
    "attrition_df[\"HumanResourcesEducationBool\"] = attrition_df.EducationField[attrition_df.EducationField == 'Human Resources']\n",
    "# attrition_df[\"EducationField\"] = attrition_df.EducationField.map({'Life Sciences': 0, 'Other': 1, 'Medical': 2, 'Marketing': 3, 'Technical Degree': 4,\n",
    "# #  'Human Resources': 5})\n",
    "\n",
    "\n",
    "# attrition_df[\"Gender\"] = attrition_df.Gender.map({\"Male\": 0, \"Female\": 1})\n",
    "attrition_df[\"Male\"] = attrition_df.Gender[attrition_df.Gender == 'Male']\n",
    "attrition_df[\"Female\"] = attrition_df.Gender[attrition_df.Gender == 'Female']\n",
    "\n",
    "\n",
    "\n",
    "attrition_df[\"SalesExecutiveBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Sales Executive']\n",
    "attrition_df[\"ResearchScientistBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Research Scientist']\n",
    "attrition_df[\"LaboratoryTechnicianBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Laboratory Technician']\n",
    "attrition_df[\"ManufacturingDirectorBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Manufacturing Director']\n",
    "attrition_df[\"HealthcareRepresentativeBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Healthcare Representative']\n",
    "attrition_df[\"ManagerBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Manager']\n",
    "attrition_df[\"SalesRepresentativeBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Sales Representative']\n",
    "attrition_df[\"ResearchDirectorBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Research Director']\n",
    "attrition_df[\"HumanResourcesBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Human Resources']\n",
    "\n",
    "\n",
    "# # attrition_df[\"JobRole\"] = attrition_df.JobRole.map({'Sales Executive': 0, 'Research Scientist': 1,\n",
    "# #     'Laboratory Technician': 2, 'Manufacturing Director': 3, 'Healthcare Representative': 4, 'Manager': 5,\n",
    "# #  'Sales Representative': 6, 'Research Director': 7, 'Human Resources': 8})\n",
    "\n",
    "\n",
    "\n",
    "attrition_df[\"DivorcedBool\"] = attrition_df.MaritalStatus[attrition_df.MaritalStatus == 'Divorced']\n",
    "attrition_df[\"SingleBool\"] = attrition_df.MaritalStatus[attrition_df.MaritalStatus == 'Single']\n",
    "attrition_df[\"MarriedBool\"] = attrition_df.MaritalStatus[attrition_df.MaritalStatus == 'Married']\n",
    "# # attrition_df[\"MaritalStatus\"] = attrition_df.MaritalStatus.map({'Single': 0, 'Married': 1, 'Divorced': 2})\n",
    "\n",
    "attrition_df[\"OverTimeBool\"] = attrition_df.OverTime.map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "\n",
    "# attrition_df[\"OverTime\"] = attrition_df.OverTime.map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# # attrition_df[\"Over18\"] = attrition_df.Over18.map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "# # attrition_df\n",
    "\n",
    "# # # attrition_df.Education\n",
    "\n",
    "\n",
    "# # # for cat_data in attrition_df[pre_categorized_data + post_categorical_data]:\n",
    "# # # #     print(cat_data, ' : ',attrition_df[cat_data].mode)\n",
    "# # #     print(cat_data)\n",
    "    \n",
    "# # # attrition_df[pre_categorized_data + post_categorical_data].Education.mode()\n",
    "# attrition_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition_df[\"TravelRarelyBool\"]\n",
    "attrition_df[\"TravelRarelyBool\"] = attrition_df[\"TravelRarelyBool\"].map({\"Travel_Rarely\": 1, np.nan: 0})\n",
    "# attrition_df[\"TravelRarelyBool\"]\n",
    "\n",
    "attrition_df[\"NonTravelBool\"] = attrition_df[\"NonTravelBool\"].map({\"Non-Travel\": 1, np.nan: 0})\n",
    "attrition_df[\"TravelFrequentlyBool\"] = attrition_df[\"TravelFrequentlyBool\"].map({\"Travel_Frequently\": 1, np.nan: 0})\n",
    "\n",
    "# # attrition_df[\"NonTravelBool\"]\n",
    "\n",
    "\n",
    "attrition_df[\"SalesDepartmentBool\"] = attrition_df[\"SalesDepartmentBool\"].map({\"Sales\": 1, np.nan: 0})\n",
    "attrition_df[\"ResearchAndDevelopmentDepartmentBool\"] = attrition_df[\"ResearchAndDevelopmentDepartmentBool\"].map({\"Research & Development\": 1, np.nan: 0})\n",
    "attrition_df[\"HumanResourcesDepartmentBool\"] = attrition_df[\"HumanResourcesDepartmentBool\"].map({\"Human Resources\": 1, np.nan: 0})\n",
    "\n",
    "\n",
    "attrition_df[\"LifeScienceEducationBool\"] = attrition_df[\"LifeScienceEducationBool\"].map({\"Life Sciences\": 1, np.nan: 0})\n",
    "attrition_df[\"OtherEducationBool\"] = attrition_df[\"OtherEducationBool\"].map({\"Other\": 1, np.nan: 0})\n",
    "attrition_df[\"MedicalEducationBool\"] = attrition_df[\"MedicalEducationBool\"].map({\"Medical\": 1, np.nan: 0})\n",
    "attrition_df[\"MarketingEducationBool\"] = attrition_df[\"MarketingEducationBool\"].map({\"Marketing\": 1, np.nan: 0})\n",
    "attrition_df[\"TechnicalEducationBool\"] = attrition_df[\"TechnicalEducationBool\"].map({\"Technical Degree\": 1, np.nan: 0})\n",
    "attrition_df[\"HumanResourcesEducationBool\"] = attrition_df[\"HumanResourcesEducationBool\"].map({\"Human Resources\": 1, np.nan: 0})\n",
    "\n",
    "attrition_df[\"Male\"] = attrition_df.Male.map({\"Male\": 1, np.nan: 0})\n",
    "attrition_df[\"Female\"] = attrition_df.Female.map({\"Female\": 1, np.nan: 0})\n",
    "\n",
    "\n",
    "\n",
    "# attrition_df[\"SalesExecutiveBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Sales Executive']\n",
    "# attrition_df[\"ResearchScientistBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Research Scientist']\n",
    "# attrition_df[\"LaboratoryTechnicianBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Laboratory Technician']\n",
    "# attrition_df[\"ManufacturingDirectorBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Manufacturing Director']\n",
    "# attrition_df[\"HealthcareRepresentativeBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Healthcare Representative']\n",
    "# attrition_df[\"ManagerBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Manager']\n",
    "# attrition_df[\"SalesRepresentativeBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Sales Representative']\n",
    "# attrition_df[\"ResearchDirectorBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Research Director']\n",
    "# attrition_df[\"HumanResourcesBool\"] = attrition_df.JobRole[attrition_df.JobRole == 'Human Resources']\n",
    "\n",
    "\n",
    "attrition_df[\"SalesExecutiveBool\"] = attrition_df[\"SalesExecutiveBool\"].map({\"Sales Executive\": 1, np.nan: 0})\n",
    "attrition_df[\"ResearchScientistBool\"] = attrition_df[\"ResearchScientistBool\"].map({\"Research Scientist\": 1, np.nan: 0})\n",
    "attrition_df[\"LaboratoryTechnicianBool\"] = attrition_df[\"LaboratoryTechnicianBool\"].map({\"Laboratory Technician\": 1, np.nan: 0})\n",
    "attrition_df[\"ManufacturingDirectorBool\"] = attrition_df[\"ManufacturingDirectorBool\"].map({\"Manufacturing Director\": 1, np.nan: 0})\n",
    "attrition_df[\"HealthcareRepresentativeBool\"] = attrition_df[\"HealthcareRepresentativeBool\"].map({\"Healthcare Representative\": 1, np.nan: 0})\n",
    "attrition_df[\"ManagerBool\"] = attrition_df[\"ManagerBool\"].map({\"Manager\": 1, np.nan: 0})\n",
    "attrition_df[\"SalesRepresentativeBool\"] = attrition_df[\"SalesRepresentativeBool\"].map({\"Sales Representative\": 1, np.nan: 0})\n",
    "attrition_df[\"ResearchDirectorBool\"] = attrition_df[\"ResearchDirectorBool\"].map({\"Research Director\": 1, np.nan: 0})\n",
    "attrition_df[\"HumanResourcesBool\"] = attrition_df[\"HumanResourcesBool\"].map({\"Human Resources\": 1, np.nan: 0})\n",
    "\n",
    "# attrition_df\n",
    "\n",
    "\n",
    "\n",
    "attrition_df[\"DivorcedBool\"] = attrition_df[\"DivorcedBool\"].map({\"Divorced\": 1, np.nan: 0})\n",
    "attrition_df[\"SingleBool\"] = attrition_df[\"SingleBool\"].map({\"Single\": 1, np.nan: 0})\n",
    "attrition_df[\"MarriedBool\"] = attrition_df[\"MarriedBool\"].map({\"Married\": 1, np.nan: 0})\n",
    "\n",
    "# attrition_df.JobRole.unique()\n",
    "attrition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET MODE FOR ALL CATEGORICAL DATA\n",
    "attrition_df[pre_categorized_data + post_categorical_data].mode().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIND SERIES WITH NO VARIANCE/SINGLE VALUE -> THESE SERIES DO NOT HOLD PREDICTIVE VALUE AND CAN BE DROPPED\n",
    "for series in attrition_df.columns:\n",
    "        if (len(attrition_df[series].unique()) <= 1): print(series, ' : ', attrition_df[series].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df = attrition_df.drop(columns=[\"EducationFieldEmployeeCount\", \"Over18\", \"StandardHours\"])\n",
    "\n",
    "\n",
    "# attrition_df.Over18\n",
    "\n",
    "# attrition_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL NONCATEGORICAL DATA\n",
    "attrition_df.head\n",
    "\n",
    "len(list(attrition_df))\n",
    "\n",
    "list(attrition_df)\n",
    "##mean range median mode(mrm) this is to get mean, range, mode and median for all noncategorical data\n",
    "series_mrm = [\n",
    "    'Age',\n",
    "    'DailyRate',\n",
    "    'DistanceFromHome',\n",
    "    'EnvironmentSatisfaction',\n",
    "    'HourlyRate',\n",
    "    \"JobSatisfaction\",\n",
    "    \"MonthlyIncome\",\n",
    "    \"MonthlyRate\",\n",
    "    \"NumCompaniesWorked\",\n",
    "    \"PercentSalaryHike\",\n",
    "    \"PerformanceRating\",\n",
    "    \"RelationshipSatisfaction\",\n",
    "    \"StockOptionLevel\",\n",
    "    \"TotalWorkingYears\",\n",
    "    \"TrainingTimesLastYear\",\n",
    "    \"WorkLifeBalance\",\n",
    "    \"YearsAtCompany\",\n",
    "    \"YearsInCurrentRole\",\n",
    "    \"YearsSinceLastPromotion\",\n",
    "    \"YearsWithCurrManager\"\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attrition_df.applymap(type).eq(str).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #converts all data types to floats\n",
    "\n",
    "# for series in attrition_df.columns:\n",
    "#     if series == \"DailyRate\":\n",
    "#         print('found series')\n",
    "#         print(attrition_df[series].dtype)\n",
    "#     if  attrition_df[series].dtype != 'object':\n",
    "# #         attrition_df[series] = attrition_df[series].astype(float)\n",
    "#           if series == 'AttritionBool':\n",
    "#             print('found ' + 'AttritionBool' )\n",
    "#           attrition_df[series] = pd.to_numeric(series)\n",
    "#     if series == \"DailyRate\":\n",
    "#         print(type(attrition_df[series]))\n",
    "# #     print(attrition_df[series].dtype)\n",
    "# #     if  attrition_df[series].dtype == 'object':\n",
    "# #         print('is object')\n",
    "\n",
    "# # attrition_df.head()\n",
    "\n",
    "# attrition_df.applymap(type).eq(str).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirms that data types are no longer strings\n",
    "# attrition_df.applymap(type).eq(str).all()\n",
    "\n",
    "#assert\n",
    "\n",
    "# attrition_df.Attrition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# attrition_df[series_mrm].mean()\n",
    "# attrition_df.Age.mean()\n",
    "\n",
    "# type(attrition_df.Age.iloc[0])\n",
    "\n",
    "#convert all data from string type to float\n",
    "\n",
    "\n",
    "attrition_df[series_mrm].mean()\n",
    "attrition_df[series_mrm].mode()\n",
    "attrition_df[series_mrm].median()\n",
    "# attrition_df[series_mrm].range()\n",
    "\n",
    "# range = attrition_df.max() - attrition_df.min()\n",
    "\n",
    "# range = (range ^ 2) / range\n",
    "\n",
    "\n",
    "# range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONFIRM NULL VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Categorical Data To Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Data\n",
    "\n",
    "'Attrition' \n",
    "\n",
    "Will be converted from 'yes' & 'no' to 1 & 0 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrition_df.columns = attrition_df.columns.str.lower()\n",
    "attrition_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFIRM NULL VALUES\n",
    "attrition_df.isnull().values.any().sum()\n",
    "print(\"Missing Values, Detail:\", '\\n', attrition_df.isnull().sum())\n",
    "print('Total Missing Values:', attrition_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df['Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.Education.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints the mean of non categorical data\n",
    "# for column in attrition_df:\n",
    "#     if not column in [pre_categorized_data + post_categorical_data]:\n",
    "#         pp(column)\n",
    "#         pp(attrition_df[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.BusinessTravel.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirms that data types are no longer strings\n",
    "attrition_df.applymap(type).eq(str).all()\n",
    "# attrition_df.YearsWithCurrManager\n",
    "attrition_df.TravelFrequentlyBool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.DailyRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.head(1)\n",
    "\n",
    "list(attrition_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I predict that\n",
    "\n",
    "- age\n",
    "- education\n",
    "- environmentsatisfaction\n",
    "- monthlyrate\n",
    "- hourlyrate\n",
    "- dailyrate\n",
    "\n",
    "will be factors/features that will be predictive in finding employee attrition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesized_predictors = [\n",
    "# \"Age\",\n",
    "# \"Education\",\n",
    "# \"EnvironmentSatisfaction\",\n",
    "# \"MonthlyRate\",\n",
    "# \"HourlyRate\",\n",
    "# \"DailyRate\"\n",
    "# ]\n",
    "\n",
    "# # EnvironmentSatisfaction\n",
    "# # 1 'Low' 2 'Medium' 3 'High' 4 'Very High'\n",
    "# data_env_sat = {'Low': 1, 'Medium': 2, 'High': 3, 'Very High': 4}\n",
    "# data_env_sat_names = list(data_env_sat.keys())\n",
    "# data_env_sat_values = list(data_env_sat.values())\n",
    "\n",
    "# # Education\n",
    "# # 1 'Below College' 2 'College' 3 'Bachelor' 4 'Master' 5 'Doctor'\n",
    "# data_edu = {'Below College': 1, 'College': 2, 'Bachelor': 3, 'Master': 4, 'Doctor': 5}\n",
    "# data_edu_names = list(data_edu.keys())\n",
    "# data_edu_values = list(data_edu.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sns.regplot(y=attrition_df['AttritionBool'], x=attrition_df[\"DailyRate\"], data=attrition_df)\n",
    "# type(attrition_df[\"DailyRate\"].unique()[0])\n",
    "# # attrition_df['AttritionBool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sns.set_style('ticks')\n",
    "\n",
    "# sns.regplot(x=attrition_df['Attrition'], y=attrition_df[\"DailyRate\"], data=attrition_df)\n",
    "\n",
    "# # sns.set_style('ticks')\n",
    "# # fig, ax = plt.subplots()\n",
    "# # fig.set_size_inches(18.5, 10.5)\n",
    "# # sns.regplot(data[:,0], data[:,1], ax=ax)\n",
    "# # sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for factor in hypothesized_predictors:\n",
    "#     print(factor)\n",
    "#     if factor == \"Education\":\n",
    "#         fig, axs = plt.subplots(1, 3, figsize=(9,3), sharey=True)\n",
    "\n",
    "#         axs[0].bar(data_env_sat_names, data_env_sat_values)\n",
    "#         for xtick in axs[0].get_xticklabels():\n",
    "#             xtick.set_rotation(45)\n",
    "        \n",
    "#         axs[1].scatter(data_env_sat_names, data_env_sat_values)\n",
    "#         for xtick in axs[1].get_xticklabels():\n",
    "#             xtick.set_rotation(45)\n",
    "        \n",
    "#         axs[2].plot(data_env_sat_names, data_env_sat_values)\n",
    "#         for xtick in axs[2].get_xticklabels():\n",
    "#             xtick.set_rotation(45)\n",
    "        \n",
    "#         fig.suptitle('Categorical Plotting of Education')\n",
    "\n",
    "#     elif factor == \"EnvironmentSatisfaction\":\n",
    "#         fig, axs = plt.subplots(1, 3, figsize=(9,3), sharey=True)\n",
    "        \n",
    "#         axs[0].bar(data_edu_names, data_edu_values)\n",
    "#         for xtick in axs[0].get_xticklabels():\n",
    "#             xtick.set_rotation(45)\n",
    "        \n",
    "#         axs[1].scatter(data_edu_names, data_edu_values)\n",
    "#         for xtick in axs[1].get_xticklabels():\n",
    "#             xtick.set_rotation(45)\n",
    "            \n",
    "#         axs[2].plot(data_edu_names, data_edu_values)\n",
    "#         axs[2].tick_params(axis='x', which='major', pad=115)\n",
    "#         for xtick in axs[2].get_xticklabels():\n",
    "#             xtick.set_rotation(45)\n",
    "\n",
    "\n",
    "        \n",
    "#         fig.suptitle('Categorical Plotting of Environment Satisfaction')\n",
    "#     else:\n",
    "#         plt.hist((attrition_df[factor]), bins=25, ec='black')\n",
    "#         plt.xlabel(factor)\n",
    "#         plt.ylabel('Count')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(attrition_df.Age, bins=25, ec='black')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "# from sklearn import cross_validation, neighbors\n",
    "\n",
    "# OLD\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import grid_search, cross_validation, neighbors\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeNumber',\n",
    "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate', 'JobInvolvement',\n",
    "       'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
    "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'OverTime',\n",
    "       'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction',\n",
    "       'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
    "       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "       'YearsSinceLastPromotion', 'YearsWithCurrManager', 'AttritionBool',\n",
    "       'TravelRarelyBool', 'TravelFrequentlyBool', 'NonTravelBool',\n",
    "       'SalesDepartmentBool', 'ResearchAndDevelopmentDepartmentBool',\n",
    "       'HumanResourcesDepartmentBool', 'LifeScienceEducationBool',\n",
    "       'OtherEducationBool', 'MedicalEducationBool', 'MarketingEducationBool',\n",
    "       'TechnicalEducationBool', 'HumanResourcesEducationBool', 'Male',\n",
    "       'Female', 'SalesExecutiveBool', 'ResearchScientistBool',\n",
    "       'LaboratoryTechnicianBool', 'ManufacturingDirectorBool',\n",
    "       'HealthcareRepresentativeBool', 'ManagerBool',\n",
    "       'SalesRepresentativeBool', 'ResearchDirectorBool', 'HumanResourcesBool',\n",
    "       'DivorcedBool', 'SingleBool', 'MarriedBool', 'OverTimeBool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting features and predictors for models\n",
    "X = attrition_df.drop(['Attrition', 'AttritionBool', 'OverTime', 'Department', 'BusinessTravel', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus'], axis=1)\n",
    "# X = attrition_df.drop(['Attrition', 'AttritionBool', 'Over18', 'Department', 'BusinessTravel', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus'], axis=1)\n",
    "\n",
    "y = attrition_df.AttritionBool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET BASELINE\n",
    "\n",
    "def get_baseline():\n",
    "    print(y_test.value_counts()[0] / y_test.size if (y_test.value_counts()[0] / y_test.size) > (y_test.value_counts()[1] / y_test.size) else y_test.value_counts()[1] / y_test.size)  \n",
    "\n",
    "get_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.precision_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall, the ability to predict true positives  tp / tp + fn\n",
    "metrics.recall_score(y_test,y_pred_class)\n",
    "# metrics.recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #ATTEMPT AT MANUAL CROSS VALIDATION, COULD BE USEFULE FOR OTHER MODELS\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# def finding_best_kN_value(value=100):\n",
    "#     list_of_percentages = []\n",
    "#     for i in list(range(1, value)):\n",
    "#         knn = KneighborsClassifier(n_neighbors=i)\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "#         knn.fit(X_train, y_train)\n",
    "        \n",
    "#         y_pred_class = knn.predict(X_test)\n",
    "        \n",
    "#         if y_pred_class > max(list_of_percentages): \n",
    "#             list_of_percentages.append(metrics.accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "#     return list_of_percentages\n",
    "\n",
    "# finding_best_kN_value()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(knn, X, y, cv=100, scoring=\"accuracy\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(range(1, 101))\n",
    "params = {'n_neighbors': k}\n",
    "kf = cross_validation.KFold(len(attrition_df), n_folds=5)\n",
    "gs = grid_search.GridSearchCV(\n",
    "    estimator = neighbors.KNeighborsClassifier(),\n",
    "    param_grid=params,\n",
    "    cv=kf\n",
    ")\n",
    "\n",
    "#NEW VERSION\n",
    "# gs = GridSearchCV(\n",
    "#     estimator = neighbors.KNeighborsClassifier(),\n",
    "#     param_grid=params,\n",
    "#     cv=kf,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "gs.fit(X, y)\n",
    "gs.grid_scores_\n",
    "\n",
    "\n",
    "# lowest_std = []\n",
    "# highest_mean = []\n",
    "# for values in gs.grid_scores_:\n",
    "# #     print(values[1])\n",
    "# #     print(type(values[1]))\n",
    "# #     print(lowest_std[0][1])\n",
    "# #     print(lowest_std[0])\n",
    "#     if len(highest_mean) == 0:\n",
    "#         highest_mean.append(values)\n",
    "#     else:# values[1] > lowest_std[0][1]:\n",
    "#         highest_mean.pop()\n",
    "#         highest_mean.append(values)\n",
    "        \n",
    "#     if len(lowest_std) == 0:\n",
    "#         lowest_std.append(values)\n",
    "#     else:# values[1] > lowest_std[0][1]:\n",
    "#         lowest_std.pop()\n",
    "#         lowest_std.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(gs.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowest_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linreg.intercept_)\n",
    "print(linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Best Predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrition_formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('MonthlyIncome',), 0.3365711649120964],\n",
       " [('TotalWorkingYears',), 0.3337660489567392],\n",
       " [('OverTimeBool',), 0.3239614255529005],\n",
       " [('MonthlyIncome', 'TotalWorkingYears'), 0.33463412506852913],\n",
       " [('MonthlyIncome', 'OverTimeBool'), 0.3198337345310833],\n",
       " [('TotalWorkingYears', 'OverTimeBool'), 0.31624216504720976]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_test_rmse(feature_cols):\n",
    "    X = attrition_df[feature_cols]\n",
    "    y = attrition_df.AttritionBool\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    \n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "\n",
    "\n",
    "features = [col for col in attrition_df.columns if col in (['OverTimeBool', 'TotalWorkingYears', 'MonthlyIncome'])]\n",
    "feature_data_list_holder= []\n",
    "\n",
    "\n",
    "for feature in range(1, len(features)):\n",
    "    for subset in itertools.combinations(features, feature):\n",
    "        score = train_test_rmse(list(subset))\n",
    "        feature_data_list_holder.append([subset, score])\n",
    "\n",
    "feature_data_list_holder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Null RootMeanSquareError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478, 0.13043478, 0.13043478,\n",
       "       0.13043478, 0.13043478, 0.13043478])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "\n",
    "y_null = np.zeros_like(y_test, dtype=float)\n",
    "\n",
    "y_null.fill(y_test.mean())\n",
    "y_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33678116053977536"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(metrics.mean_squared_error(y_test, y_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - ROC curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "\n",
    "y_pred_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('metrics.accuracy_score : ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('metrics.recall_score : ', metrics.recall_score(y_test,y_pred_class))\n",
    "print('metrics.precision_score : ', metrics.precision_score(y_test, y_pred_class))\n",
    "print('metrics.f1_score : ', metrics.f1_score(y_test, y_pred_class))\n",
    "print('metrics.confusion_matrix : ', metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT CONFUSION MATRIX RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true negative tn, false positive fp, false negative fn, true positivie = tp\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred_class).ravel()\n",
    "\n",
    "print('TN:{} | FP:{} | FN:{} | TP:{}'.format(tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "print(metrics.classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC curves and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_for_roc_auc = logreg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob_for_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_prob_for_roc_auc)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate -> FP/(FP+TN)')\n",
    "plt.ylabel('True Positivie Rate -> Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.roc_auc_score(y_test, y_pred_prob_for_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done with KNN for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# histogram of predicted probabilities grouped by actual response value\n",
    "df = pd.DataFrame({'probability':y_pred_prob_for_roc_auc, 'actual':y_test})\n",
    "df.hist(column='probability', by='actual', sharex=True, sharey=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE ITERMETHOS TO GO THROUGH ALL COMBINATIONS AND FIND THE BEST CROSS VAL SCORE\n",
    "\n",
    "\n",
    "EXAMPLE:\n",
    "# # add Fare to the model\n",
    "# feature_cols = ['Pclass', 'Parch', 'Age', 'Sex_Female', 'Embarked_Q', 'Embarked_S', 'Fare']\n",
    "# X = titanic[feature_cols]\n",
    "\n",
    "# # recalculate AUC\n",
    "# cross_val_score(logreg, X, y, cv=10, scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree -> Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeClf = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "DTscores = cross_val_score(treeClf, X, y, cv=14, scoring='neg_mean_squared_error')\n",
    "np.mean(np.sqrt(-DTscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeClfDep1 = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "\n",
    "DTscores = cross_val_score(treeClfDep1, X, y, cv=14, scoring='neg_mean_squared_error')\n",
    "np.mean(np.sqrt(-DTscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_range = range(1,8)\n",
    "\n",
    "# list to store values\n",
    "RMSE_scores = []\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    treeClf = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    MSE_scores = cross_val_score(treeClf, X, y, cv=14, scoring=\"neg_mean_squared_error\")\n",
    "    RMSE_scores.append(np.mean(np.sqrt(-MSE_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(max_depth_range, RMSE_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE (lower is better)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeClf = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "treeClf.fit(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "treereg.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'feature': X.columns, 'importance': treereg.feature_importances_})\n",
    "values = pd.DataFrame({'feature': X.columns, 'importance': treeClf.feature_importances_}).sort_values(by='importance', ascending=False)\n",
    "values.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO\n",
    "import pydot\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "export_graphviz(treeClf, out_file='tree_attrition.dot', feature_names=X.columns)\n",
    "!dot -Tpng tree_attrition.dot -o tree_attrition.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open('tree_attrition.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using The Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(attrition_df[\"AttritionBool\"])\n",
    "# pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X\n",
    "y_test = y\n",
    "y_pred = treeClf.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "# X_test.OverTimeBool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "#i don't know if this is good or bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
